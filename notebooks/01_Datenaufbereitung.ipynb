{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01_Datenaufbereitung (CSV → Parquet)\n",
    "\n",
    "Dieses Notebook:\n",
    "- erstellt eine **SparkSession**\n",
    "- definiert **Schemas** für Hub/Spoke\n",
    "- liest die Original-CSV Dateien ein\n",
    "- führt **Parsing/Cleansing** durch (z.B. `\"-\"` → `null`, Timestamp-Parsing, Feature-Vector-Parsing)\n",
    "- speichert die bereinigten Daten als **Parquet**\n",
    "\n",
    "> **Hinweis:** Pfade sind standardmäßig auf die hochgeladenen Dateien in dieser Umgebung gesetzt. Wenn ihr das Notebook in eurem Repo/Cluster nutzt, passt die Pfade im nächsten Cell an.\n"
   ],
   "id": "2e05e2783cf83707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:26.019974Z",
     "start_time": "2025-12-21T16:37:26.014196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "# nur auf ZHAW-Cluster nötig\n",
    "# import swissproc\n",
    "# sc = swissproc.connect(\"frommthi\", 2)\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pyspark.sql\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import col, unix_timestamp, from_unixtime, date_format, to_timestamp, round, when\n",
    "\n"
   ],
   "id": "639652f19fe24a60",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:26.036994Z",
     "start_time": "2025-12-21T16:37:26.030848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pfade\n",
    "\n",
    "# --- INPUT: Originaldateien ---\n",
    "HUB_CSV = \"data/raw/dm-hub.csv\"\n",
    "SPOKE_CSV = \"data/raw/dm-spoke.csv\"\n",
    "METEO_CSV = \"data/raw/ogd-smn-precip_leu_t_recent.csv\"\n",
    "\n",
    "# --- OUTPUT: Parquet-Zielordner ---\n",
    "OUT_ROOT = \"data/processed\"\n",
    "HUB_OUT_PARQUET = os.path.join(OUT_ROOT, \"hub\")\n",
    "SPOKE_OUT_PARQUET = os.path.join(OUT_ROOT, \"spoke\")\n",
    "METEO_OUT_PARQUET = os.path.join(OUT_ROOT, \"meteo\")\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "print(\"HUB_CSV:\", HUB_CSV)\n",
    "print(\"SPOKE_CSV:\", SPOKE_CSV)\n",
    "print(\"OUT_ROOT:\", OUT_ROOT)\n"
   ],
   "id": "518f0713857bec1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUB_CSV: data/raw/dm-hub.csv\n",
      "SPOKE_CSV: data/raw/dm-spoke.csv\n",
      "OUT_ROOT: data/processed\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Datenaufbereitung Hubs\n",
    "Die Daten der Hubs enthält folgende Spalten:\n",
    "- `hubtracker`: Eindeutige ID des Hubs\n",
    "- `timestamp_hubs`: Zeitstempel der Messung (Unix-Epoche in Sekunden -> DD.MM.YYYY HH:MM)\n",
    "- `hub_coords`: Koordinaten des Hubs als String `<latitude> <longitude>`\n",
    "- `lat_hubs`: Latitude des Hubs (Dezimalgrad)\n",
    "- `lon_hubs`: Longitude des Hubs (Dezimalgrad)\n",
    "- `voltage`: Spannung des Hubs in Volt\n",
    "- `temperature_hubs`: Temperatur des Hubs in Grad Celsius\n",
    "- `signal`: Signalstärke des Hubs (nicht benötigt)\n",
    "- `timestamp_10min`: Zeitstempel der Messung auf 10-Minuten-Intervall gerundet (wird erstellt)\n"
   ],
   "id": "89f1d19941455807"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:26.506779Z",
     "start_time": "2025-12-21T16:37:26.047387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hub-Format: <hubtracker> <timestamp> hub-coords <latitude> <longitude> <voltage/V> <temperature/°C> <signal>\n",
    "# => 8 Spalten (signal ist die 8. Spalte, wird aber nicht benötigt)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "hubs = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"false\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(HUB_CSV)\n",
    "    .toDF(\n",
    "        \"hubtracker\",\n",
    "        \"timestamp_hubs\",\n",
    "        \"hub_coords\",\n",
    "        \"lat_hubs\",\n",
    "        \"lon_hubs\",\n",
    "        \"voltage\",\n",
    "        \"temperature_hubs\",\n",
    "        \"signal\"\n",
    "    )\n",
    "    .select(\"hubtracker\", \"timestamp_hubs\", \"lat_hubs\", \"lon_hubs\")\n",
    "    .withColumn(\n",
    "        \"timestamp_hubs_ts\",\n",
    "        from_unixtime(col(\"timestamp_hubs\")).cast(\"timestamp\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"timestamp_10min\",\n",
    "        from_unixtime(\n",
    "            (unix_timestamp(col(\"timestamp_hubs_ts\")) / 600).cast(\"long\") * 600\n",
    "        ).cast(\"timestamp\")\n",
    "    )\n",
    "\n",
    "    # Datentypen\n",
    "    .withColumn(\"lat_hubs\", col(\"lat_hubs\").cast(\"double\"))\n",
    "    .withColumn(\"lon_hubs\", col(\"lon_hubs\").cast(\"double\"))\n",
    "\n",
    "    .dropna()\n",
    ")\n",
    "    # .dropDuplicates([\"hubtracker\"])\n",
    "\n",
    "hubs.write.mode(\"overwrite\").parquet(HUB_OUT_PARQUET)\n",
    "hubs_parquet = spark.read.parquet(HUB_OUT_PARQUET)\n",
    "\n",
    "hubs_parquet.printSchema()\n",
    "print(f\"Hub-Verarbeitung: {time.time() - start:.2f} Sekunden\")\n",
    "print(f\"Anzahl Hubs: {hubs_parquet.count()}\")"
   ],
   "id": "798606240bd57c71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hubtracker: integer (nullable = true)\n",
      " |-- timestamp_hubs: long (nullable = true)\n",
      " |-- lat_hubs: double (nullable = true)\n",
      " |-- lon_hubs: double (nullable = true)\n",
      " |-- timestamp_hubs_ts: timestamp (nullable = true)\n",
      " |-- timestamp_10min: timestamp (nullable = true)\n",
      "\n",
      "Hub-Verarbeitung: 0.41 Sekunden\n",
      "Anzahl Hubs: 46757\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:26.551590Z",
     "start_time": "2025-12-21T16:37:26.516030Z"
    }
   },
   "cell_type": "code",
   "source": "hubs_parquet.show(10)",
   "id": "5477ac8ea7f02eb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------+---------+-------------------+-------------------+\n",
      "|hubtracker|timestamp_hubs|  lat_hubs| lon_hubs|  timestamp_hubs_ts|    timestamp_10min|\n",
      "+----------+--------------+----------+---------+-------------------+-------------------+\n",
      "|    937832|    1752294998|46.3694617|7.6737851|2025-07-12 06:36:38|2025-07-12 06:30:00|\n",
      "|    932400|    1752295123|46.3693767|7.6737784|2025-07-12 06:38:43|2025-07-12 06:30:00|\n",
      "|    937832|    1752294998|46.3694617|7.6737851|2025-07-12 06:36:38|2025-07-12 06:30:00|\n",
      "|    937832|    1752294998|46.3694617|7.6737851|2025-07-12 06:36:38|2025-07-12 06:30:00|\n",
      "|    937832|    1752294998|46.3694617|7.6737851|2025-07-12 06:36:38|2025-07-12 06:30:00|\n",
      "|    932400|    1752295123|46.3693767|7.6737784|2025-07-12 06:38:43|2025-07-12 06:30:00|\n",
      "|    938223|    1752295183| 46.369405|7.6746084|2025-07-12 06:39:43|2025-07-12 06:30:00|\n",
      "|    938223|    1752295183| 46.369405|7.6746084|2025-07-12 06:39:43|2025-07-12 06:30:00|\n",
      "|    938223|    1752295183| 46.369405|7.6746084|2025-07-12 06:39:43|2025-07-12 06:30:00|\n",
      "|    937832|    1752294998|46.3694617|7.6737851|2025-07-12 06:36:38|2025-07-12 06:30:00|\n",
      "+----------+--------------+----------+---------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Datenaufbereitung Spokes\n",
    "Die Daten der Spokes enthält folgende Spalten:\n",
    "- `hubtracker`: Eindeutige ID des Hubs, der den Spoke emp\n",
    "- `timestamp_spokes`: Zeitstempel der Messung (Unix-Epoche in Sekunden -> DD.MM.YYYY HH:MM)\n",
    "- `spoke_visibility`: Sichtbarkeit des Spokes (Boolean)\n",
    "- `spoketracker`: Eindeutige ID des Spokes (Tier)\n",
    "- `rssi`: Signalstärke des Spokes in dB\n",
    "- `device_state`: Zustand des Geräts (z.B. \"OK\", \"LOW_BATTERY\", etc.)\n",
    "- `voltage`: Spannung des Spokes in Volt\n",
    "- `temperature_spokes`: Temperatur des Spokes in Grad Celsius\n",
    "- `animal_state`: Zustand des Tiers (z.B. \"RESTING\", \"WALKING\", etc.)\n",
    "- `state_resting`: Zeit in Minuten, die das Tier ruhend verbracht hat\n",
    "- `state_walking`: Zeit in Minuten, die das Tier gehend verbracht hat\n",
    "- `state_grazing`: Zeit in Minuten, die das Tier grast verbracht hat\n",
    "- `state_running`: Zeit in Minuten, die das Tier rennend verbracht hat\n",
    "- `spoke_ts`: Zeitstempel der Messung als Timestamp\n",
    "- `spoke_ts_10min`: Zeitstempel der Messung auf 10-Minuten-Intervall gerundet"
   ],
   "id": "3467b65d35a4e120"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:27.292279Z",
     "start_time": "2025-12-21T16:37:26.570544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Spoke-Format: <hubtracker> <timestamp> spoke-visibility <spoketracker> <rssi/dB> <device-state>\n",
    "#               <voltage/V> <temperature/°C> <animal-state> <state-resting/min> <state-walking/min>\n",
    "#               <state-grazing/min> <state-running/min> <f01> ... <f15> <extra>\n",
    "# => 29 Spalten (15 Feature-Werte als einzelne Spalten)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Spaltennamen für alle 29 Spalten\n",
    "spoke_cols = [\n",
    "                 \"hubtracker\", \"timestamp_spokes\", \"spoke_visibility\", \"spoketracker\",\n",
    "                 \"rssi\", \"device_state\", \"voltage\", \"temperature_spokes\", \"animal_state\",\n",
    "                 \"state_resting\", \"state_walking\", \"state_grazing\", \"state_running\"\n",
    "             ] + [f\"f{i:02d}\" for i in range(1, 16)] + [\"extra\"]\n",
    "\n",
    "spokes = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(SPOKE_CSV) \\\n",
    "    .toDF(*spoke_cols)\n",
    "\n",
    "# Nur benötigte Spalten selektieren (ohne extra-Spalte)\n",
    "spokes_selected = spokes.select(\n",
    "    \"hubtracker\",\n",
    "    \"timestamp_spokes\",\n",
    "    \"spoke_visibility\",\n",
    "    \"spoketracker\",\n",
    "    \"rssi\",\n",
    "    \"device_state\",\n",
    "    \"voltage\",\n",
    "    \"temperature_spokes\",\n",
    "    \"animal_state\",\n",
    "    \"state_resting\",\n",
    "    \"state_walking\",\n",
    "    \"state_grazing\",\n",
    "    \"state_running\",\n",
    ")\n",
    "\n",
    "# Datentypen anpassen und Timestamp-Spalten erstellen\n",
    "spokes_cleaned = (\n",
    "    spokes_selected\n",
    "    .withColumn(\n",
    "        \"spokes_ts\",\n",
    "        from_unixtime(col(\"timestamp_spokes\")).cast(\"timestamp\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"spokes_ts_10min\",\n",
    "        from_unixtime(\n",
    "            (unix_timestamp(col(\"spokes_ts\")) / 600).cast(\"long\") * 600\n",
    "        ).cast(\"timestamp\")\n",
    "    )\n",
    "    .withColumn(\"rssi\", col(\"rssi\").cast(\"double\"))\n",
    "    .withColumn(\"voltage\", col(\"voltage\").cast(\"double\"))\n",
    "    .withColumn(\"temperature_spokes\", col(\"temperature_spokes\").cast(\"double\"))\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "spokes_cleaned.write.mode(\"overwrite\").parquet(SPOKE_OUT_PARQUET)\n",
    "spokes_parquet = spark.read.parquet(SPOKE_OUT_PARQUET)\n",
    "\n",
    "spokes_parquet.printSchema()\n",
    "print(f\"Spoke-Verarbeitung: {time.time() - start:.2f} Sekunden\")\n",
    "print(f\"Anzahl Spoke-Einträge: {spokes_parquet.count()}\")\n"
   ],
   "id": "8c915599a157d9ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hubtracker: integer (nullable = true)\n",
      " |-- timestamp_spokes: integer (nullable = true)\n",
      " |-- spoke_visibility: string (nullable = true)\n",
      " |-- spoketracker: string (nullable = true)\n",
      " |-- rssi: double (nullable = true)\n",
      " |-- device_state: string (nullable = true)\n",
      " |-- voltage: double (nullable = true)\n",
      " |-- temperature_spokes: double (nullable = true)\n",
      " |-- animal_state: string (nullable = true)\n",
      " |-- state_resting: integer (nullable = true)\n",
      " |-- state_walking: integer (nullable = true)\n",
      " |-- state_grazing: integer (nullable = true)\n",
      " |-- state_running: integer (nullable = true)\n",
      " |-- spokes_ts: timestamp (nullable = true)\n",
      " |-- spokes_ts_10min: timestamp (nullable = true)\n",
      "\n",
      "Spoke-Verarbeitung: 0.64 Sekunden\n",
      "Anzahl Spoke-Einträge: 187416\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:27.349702Z",
     "start_time": "2025-12-21T16:37:27.301298Z"
    }
   },
   "cell_type": "code",
   "source": "spokes_parquet.show(10)\n",
   "id": "7668927e4488d4c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+-----------------+------+------------+-------+------------------+------------+-------------+-------------+-------------+-------------+-------------------+-------------------+\n",
      "|hubtracker|timestamp_spokes|spoke_visibility|     spoketracker|  rssi|device_state|voltage|temperature_spokes|animal_state|state_resting|state_walking|state_grazing|state_running|          spokes_ts|    spokes_ts_10min|\n",
      "+----------+----------------+----------------+-----------------+------+------------+-------+------------------+------------+-------------+-------------+-------------+-------------+-------------------+-------------------+\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-608B7C97| -98.0|   noproblem|   4.55|              15.0|     walking|         5151|         8843|         2259|         1695|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-67CA7EB0|-100.0|   noproblem|   4.55|              14.0|     walking|         4950|        11511|         1811|          512|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-C99FA3B7| -78.0|   noproblem|   4.55|              15.0|     walking|         3684|        10991|         3142|         1586|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-2902F0B8| -77.0|   noproblem|   4.55|              14.0|     running|         3594|         8097|          397|         6682|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-6AA669CF| -91.0|   noproblem|   4.55|              16.0|     running|         5892|         2722|         5421|         3163|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-C9CBB7DE| -91.0|   noproblem|   4.55|              15.0|     walking|         5049|        10446|         1607|         1831|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-15BC5AE5| -98.0|   noproblem|   4.55|              18.0|     walking|         7419|         7342|         4380|           26|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-D03AFE0F| -91.0|   noproblem|   4.55|              12.0|     walking|         4638|         6723|          399|         6681|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416279|spoke-visibility|newspoke-0CBC5B0F| -98.0|   noproblem|   4.55|              14.0|     walking|         3494|         8720|          697|         3869|2025-07-25 06:04:39|2025-07-25 06:00:00|\n",
      "|    932400|      1753416580|spoke-visibility|newspoke-13A7D142| -97.0|highactivity|   4.55|              16.0|     walking|         3435|        12260|         1545|         1131|2025-07-25 06:09:40|2025-07-25 06:00:00|\n",
      "+----------+----------------+----------------+-----------------+------+------------+-------+------------------+------------+-------------+-------------+-------------+-------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Datenaufbereitung MeteoSchweiz Niederschlagsdaten\n",
    "Niederschlagsdaten der Station Leukerbad (CH) von MeteoSchweiz\n",
    "Quelle: https://data.geo.admin.ch/ch.meteoschweiz.ogd-smn-precip/leu/ogd-smn-precip_leu_t_recent.csv\n",
    "Die Daten enthalten folgende Spalten:\n",
    "- `station_abbr`: Stations-ID (Leukerbad: LEU)\n",
    "- `reference_timestamp`: Datum/Zeit der Messung (DD-MM-YYYY HH:MM:SS) -> Auflösung: 10 Minuten\n",
    "- `rre150z0`: Niederschlagsmenge in mm\n",
    "\n",
    "Folgende Spalten werden zusätzlich erstellt:\n",
    "- `rain_h`: Niederschlagsmenge in mm/h (berechnet aus `rain_10min` * 6)\n",
    "- `rain_category`: Kategorisierung des Niederschlags in fünf Klassen:\n",
    "    - kein (0 mm/h)\n",
    "    - sehr_schwach (0.1 - 0.5 mm/h)\n",
    "    - schwach (0.6 - 2 mm/h)\n",
    "    - mässig (2.1 - 5 mm/h)\n",
    "    - stark (5.1 - 10 mm/h)\n",
    "    - sehr_stark (> 10 mm/h)"
   ],
   "id": "67394b94afc53e0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:28.030423Z",
     "start_time": "2025-12-21T16:37:27.377437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "weather = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \";\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(METEO_CSV)\n",
    "    .toDF(\"station_id\", \"meteo_timestamp\", \"rain_10min\")\n",
    "    #Timestamp parsen\n",
    "    .withColumn(\n",
    "        \"meteo_timestamp\",\n",
    "        to_timestamp(col(\"meteo_timestamp\"), \"dd.MM.yyyy HH:mm\")\n",
    "    )\n",
    "    #auf 10 Minuten abrunden\n",
    "    .withColumn(\n",
    "        \"meteo_ts_10min\",\n",
    "        from_unixtime(\n",
    "            (unix_timestamp(col(\"meteo_timestamp\")) / 600).cast(\"long\") * 600\n",
    "        ).cast(\"timestamp\")\n",
    "    )\n",
    "    #Niederschlagsmenge in mm/h berechnen und kategorisieren\n",
    "    .withColumn(\"rain_10min\", col(\"rain_10min\").cast(\"double\"))\n",
    "    .withColumn(\"rain_h\", round(col(\"rain_10min\") * 6.0, 1))\n",
    "    .withColumn(\n",
    "        \"rain_category\",\n",
    "        when(col(\"rain_h\") == 0, \"kein\")\n",
    "        .when(col(\"rain_h\") <= 0.5, \"sehr_schwach\")\n",
    "        .when(col(\"rain_h\") <= 2, \"schwach\")\n",
    "        .when(col(\"rain_h\") <= 5, \"mässig\")\n",
    "        .when(col(\"rain_h\") <= 10, \"stark\")\n",
    "        .otherwise(\"sehr_stark\")\n",
    "    )\n",
    "    #Nur benötigte Spalten behalten\n",
    "    .drop(\"meteo_timestamp\", \"station_id\")\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "weather.write.mode(\"overwrite\").parquet(METEO_OUT_PARQUET)\n",
    "weather_parquet = spark.read.parquet(METEO_OUT_PARQUET)\n",
    "\n",
    "weather_parquet.printSchema()\n",
    "\n",
    "print(f\"Meteo-Verarbeitung: {time.time() - start:.2f} Sekunden\")\n",
    "print(f\"Anzahl Meteo-Einträge: {weather_parquet.count()}\")"
   ],
   "id": "585efdd3057c2bd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rain_10min: double (nullable = true)\n",
      " |-- meteo_ts_10min: timestamp (nullable = true)\n",
      " |-- rain_h: double (nullable = true)\n",
      " |-- rain_category: string (nullable = true)\n",
      "\n",
      "Meteo-Verarbeitung: 0.60 Sekunden\n",
      "Anzahl Meteo-Einträge: 50976\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:37:28.071792Z",
     "start_time": "2025-12-21T16:37:28.039011Z"
    }
   },
   "cell_type": "code",
   "source": "weather_parquet.show(10)",
   "id": "80495bc617ed65e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------+-------------+\n",
      "|rain_10min|     meteo_ts_10min|rain_h|rain_category|\n",
      "+----------+-------------------+------+-------------+\n",
      "|       0.0|2025-01-01 00:00:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 00:10:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 00:20:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 00:30:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 00:40:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 00:50:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 01:00:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 01:10:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 01:20:00|   0.0|         kein|\n",
      "|       0.0|2025-01-01 01:30:00|   0.0|         kein|\n",
      "+----------+-------------------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Zusammenführung der Daten Spokes + Hubs + Meteo\n",
    "In diesem Schritt werden die bereinigten Daten der Spokes, Hubs und Meteo zusammengeführt, um einen umfassenden Datensatz zu erstellen, der alle relevanten Informationen für die Analyse enthält.\n",
    "\n",
    "Die Zusammenführung erfolgt in zwei Schritten:\n",
    "1. **Spokes + Hubs**: Join per `hubtracker` und `timestamp_10min` (Spokes werden den Hubs zugeordnet)\n",
    "2. **+ Meteo**: Join per `timestamp_10min` (Wetterdaten werden zeitlich zugeordnet)\n",
    "\n",
    "Da Spokes alle 5 Minuten gemessen werden, Hub und Meteo aber alle 10 Minuten, werden die Spokes-Daten auf 10-Minuten-Intervalle gerundet.\n"
   ],
   "id": "29ed0bc0d4db8737"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:44:39.763870Z",
     "start_time": "2025-12-21T16:44:36.478137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 1. Spokes + Hubs joinen per hubtracker und 10-Minuten-Timestamp\n",
    "joined_spokes_hubs = (\n",
    "    spokes_parquet.alias(\"s\")\n",
    "    .join(\n",
    "        hubs_parquet.alias(\"h\"),\n",
    "        (col(\"s.hubtracker\") == col(\"h.hubtracker\")) &\n",
    "        (col(\"s.spokes_ts_10min\") == col(\"h.timestamp_10min\")),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        # Spokes-Spalten\n",
    "        col(\"s.hubtracker\"),\n",
    "        col(\"s.timestamp_spokes\"),\n",
    "        col(\"s.spokes_ts\"),\n",
    "        col(\"s.spokes_ts_10min\"),\n",
    "        col(\"s.spoke_visibility\"),\n",
    "        col(\"s.spoketracker\"),\n",
    "        col(\"s.rssi\"),\n",
    "        col(\"s.device_state\"),\n",
    "        col(\"s.voltage\").alias(\"spoke_voltage\"),\n",
    "        col(\"s.temperature_spokes\"),\n",
    "        col(\"s.animal_state\"),\n",
    "        col(\"s.state_resting\"),\n",
    "        col(\"s.state_walking\"),\n",
    "        col(\"s.state_grazing\"),\n",
    "        col(\"s.state_running\"),\n",
    "        # Hub-Spalten\n",
    "        col(\"h.lat_hubs\"),\n",
    "        col(\"h.lon_hubs\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Meteo hinzufügen per 10-Minuten-Timestamp (broadcast weil klein)\n",
    "joined_all = (\n",
    "    joined_spokes_hubs.alias(\"sh\")\n",
    "    .join(\n",
    "        broadcast(weather_parquet.alias(\"w\")),\n",
    "        col(\"sh.spokes_ts_10min\") == col(\"w.meteo_ts_10min\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        col(\"sh.*\"),\n",
    "        col(\"w.rain_10min\"),\n",
    "        col(\"w.rain_h\"),\n",
    "        col(\"w.rain_category\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Duplikate entfernen (basierend auf spoketracker, timestamp und hubtracker)\n",
    "joined_all = joined_all.dropDuplicates([\"spoketracker\", \"timestamp_spokes\", \"hubtracker\"])\n",
    "\n",
    "# Ergebnis speichern\n",
    "JOINED_OUT_PARQUET = os.path.join(OUT_ROOT, \"joined\")\n",
    "joined_all.write.mode(\"overwrite\").parquet(JOINED_OUT_PARQUET)\n",
    "joined_parquet = spark.read.parquet(JOINED_OUT_PARQUET)\n",
    "\n",
    "joined_parquet.printSchema()\n",
    "print(f\"Join-Verarbeitung: {time.time() - start:.2f} Sekunden\")\n",
    "print(f\"Anzahl Joined-Einträge (nach Deduplizierung): {joined_parquet.count()}\")\n"
   ],
   "id": "390edd489a402850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hubtracker: integer (nullable = true)\n",
      " |-- timestamp_spokes: integer (nullable = true)\n",
      " |-- spokes_ts: timestamp (nullable = true)\n",
      " |-- spokes_ts_10min: timestamp (nullable = true)\n",
      " |-- spoke_visibility: string (nullable = true)\n",
      " |-- spoketracker: string (nullable = true)\n",
      " |-- rssi: double (nullable = true)\n",
      " |-- device_state: string (nullable = true)\n",
      " |-- spoke_voltage: double (nullable = true)\n",
      " |-- temperature_spokes: double (nullable = true)\n",
      " |-- animal_state: string (nullable = true)\n",
      " |-- state_resting: integer (nullable = true)\n",
      " |-- state_walking: integer (nullable = true)\n",
      " |-- state_grazing: integer (nullable = true)\n",
      " |-- state_running: integer (nullable = true)\n",
      " |-- lat_hubs: double (nullable = true)\n",
      " |-- lon_hubs: double (nullable = true)\n",
      " |-- rain_10min: double (nullable = true)\n",
      " |-- rain_h: double (nullable = true)\n",
      " |-- rain_category: string (nullable = true)\n",
      "\n",
      "Join-Verarbeitung: 3.17 Sekunden\n",
      "Anzahl Joined-Einträge (nach Deduplizierung): 184766\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:44:49.253823Z",
     "start_time": "2025-12-21T16:44:49.204632Z"
    }
   },
   "cell_type": "code",
   "source": "joined_parquet.show(10, truncate=False)\n",
   "id": "1aa112fd5ad48a69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------+-------------------+----------------+-----------------+------+------------+-------------+------------------+------------+-------------+-------------+-------------+-------------+----------+---------+----------+------+-------------+\n",
      "|hubtracker|timestamp_spokes|spokes_ts          |spokes_ts_10min    |spoke_visibility|spoketracker     |rssi  |device_state|spoke_voltage|temperature_spokes|animal_state|state_resting|state_walking|state_grazing|state_running|lat_hubs  |lon_hubs |rain_10min|rain_h|rain_category|\n",
      "+----------+----------------+-------------------+-------------------+----------------+-----------------+------+------------+-------------+------------------+------------+-------------+-------------+-------------+-------------+----------+---------+----------+------+-------------+\n",
      "|934910    |1634372961      |2021-10-16 10:29:21|2021-10-16 10:20:00|spoke-visibility|newspoke-0990651F|-96.0 |highactivity|4.55         |15.0              |running     |14           |167          |96           |6            |NULL      |NULL     |NULL      |NULL  |NULL         |\n",
      "|934910    |1634373261      |2021-10-16 10:34:21|2021-10-16 10:30:00|spoke-visibility|newspoke-0990651F|-94.0 |noproblem   |4.55         |15.0              |walking     |14           |170          |96           |0            |NULL      |NULL     |NULL      |NULL  |NULL         |\n",
      "|934910    |1634384838      |2021-10-16 13:47:18|2021-10-16 13:40:00|spoke-visibility|newspoke-0990651F|-75.0 |noproblem   |4.55         |18.0              |grazing     |98           |244          |107          |7            |NULL      |NULL     |NULL      |NULL  |NULL         |\n",
      "|932400    |1637269973      |2021-11-18 22:12:53|2021-11-18 22:10:00|spoke-visibility|newspoke-0990651F|-72.0 |noproblem   |4.55         |20.0              |walking     |235          |254          |125          |4            |NULL      |NULL     |NULL      |NULL  |NULL         |\n",
      "|934910    |1752299738      |2025-07-12 07:55:38|2025-07-12 07:50:00|spoke-visibility|newspoke-0990651F|-80.0 |noproblem   |4.55         |21.0              |walking     |111          |430          |63           |19           |NULL      |NULL     |0.0       |0.0   |kein         |\n",
      "|931861    |1752300044      |2025-07-12 08:00:44|2025-07-12 08:00:00|spoke-visibility|newspoke-0990651F|-79.0 |noproblem   |4.55         |21.0              |walking     |111          |435          |63           |19           |NULL      |NULL     |0.0       |0.0   |kein         |\n",
      "|937832    |1752301550      |2025-07-12 08:25:50|2025-07-12 08:20:00|spoke-visibility|newspoke-0990651F|-99.0 |noproblem   |4.55         |21.0              |walking     |111          |450          |73           |20           |46.368585 |7.6738484|0.0       |0.0   |kein         |\n",
      "|937832    |1752304551      |2025-07-12 09:15:51|2025-07-12 09:10:00|spoke-visibility|newspoke-0990651F|-82.0 |noproblem   |4.55         |19.0              |walking     |126          |466          |91           |20           |46.368585 |7.6738484|0.0       |0.0   |kein         |\n",
      "|932400    |1752307361      |2025-07-12 10:02:41|2025-07-12 10:00:00|spoke-visibility|newspoke-0990651F|-100.0|noproblem   |4.55         |19.0              |walking     |126          |490          |110          |24           |46.3679184|7.674255 |0.0       |0.0   |kein         |\n",
      "|938223    |1752309352      |2025-07-12 10:35:52|2025-07-12 10:30:00|spoke-visibility|newspoke-0990651F|-92.0 |noproblem   |4.55         |18.0              |walking     |126          |521          |111          |26           |NULL      |NULL     |0.0       |0.0   |kein         |\n",
      "+----------+----------------+-------------------+-------------------+----------------+-----------------+------+------------+-------------+------------------+------------+-------------+-------------+-------------+-------------+----------+---------+----------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T16:44:54.316787Z",
     "start_time": "2025-12-21T16:44:53.185094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Statistik: Anzahl Einträge mit/ohne Hub-/Meteo-Daten\n",
    "print(\"=== Vollständigkeit der Daten ===\")\n",
    "total_count = joined_parquet.count()\n",
    "print(f\"Total Einträge (nach Deduplizierung): {total_count}\")\n",
    "print(f\"Mit Hub-Koordinaten: {joined_parquet.filter(col('lat_hubs').isNotNull()).count()}\")\n",
    "print(f\"Mit Meteo-Daten: {joined_parquet.filter(col('rain_10min').isNotNull()).count()}\")\n",
    "print(f\"Komplett (Spoke+Hub+Meteo): {joined_parquet.filter(col('lat_hubs').isNotNull() & col('rain_10min').isNotNull()).count()}\")\n",
    "\n",
    "# Duplikate-Check (sollte 0 sein)\n",
    "duplicate_check = joined_parquet.groupBy(\"spoketracker\", \"timestamp_spokes\", \"hubtracker\").count().filter(col(\"count\") > 1).count()\n",
    "print(f\"\\nVerbleibende Duplikate: {duplicate_check} (sollte 0 sein)\")\n",
    "\n"
   ],
   "id": "e99647bf4e6fdd3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vollständigkeit der Daten ===\n",
      "Total Einträge (nach Deduplizierung): 184766\n",
      "Mit Hub-Koordinaten: 172365\n",
      "Mit Meteo-Daten: 183294\n",
      "Komplett (Spoke+Hub+Meteo): 172313\n",
      "\n",
      "Verbleibende Duplikate: 0 (sollte 0 sein)\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 Analyse und Auswertung der Daten",
   "id": "53a6905caa66354e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
